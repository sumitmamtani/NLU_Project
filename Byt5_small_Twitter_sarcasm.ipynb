{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch \n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_json_file = '/scratch/sm9669/sarcasm_detection_shared_task_twitter_training.jsonl'\n",
    "import json \n",
    "\n",
    "with open(path_to_json_file, 'r') as j:\n",
    "     json_data = [json.loads(line) for line in j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 373730.62it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "accurate = 0\n",
    "tot_tweets = 0\n",
    "\n",
    "tweets=[]\n",
    "labels=[]\n",
    "for tweet in tqdm(json_data):\n",
    "    tot_cont = \"\"\n",
    "    for con in tweet['context']:\n",
    "        tot_cont+=con \n",
    "    tot_cont+=tweet['response']\n",
    "    tweets.append(tot_cont)\n",
    "    labels.append(tweet['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_text</th>\n",
       "      <th>source_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>A minor child deserves privacy and should be k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>@USER @USER Why is he a loser ? He's just a Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>Donald J . Trump is guilty as charged . The ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>Jamie Raskin tanked Doug Collins . Collins loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SARCASM</td>\n",
       "      <td>Man ... y ’ all gone “ both sides ” the apocal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target_text                                        source_text\n",
       "0     SARCASM  A minor child deserves privacy and should be k...\n",
       "1     SARCASM  @USER @USER Why is he a loser ? He's just a Pr...\n",
       "2     SARCASM  Donald J . Trump is guilty as charged . The ev...\n",
       "3     SARCASM  Jamie Raskin tanked Doug Collins . Collins loo...\n",
       "4     SARCASM  Man ... y ’ all gone “ both sides ” the apocal..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'target_text':labels,\n",
    "        'source_text':tweets}\n",
    " \n",
    "train = pd.DataFrame(data)\n",
    " \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_json_file = '/scratch/sm9669/sarcasm_detection_shared_task_twitter_testing.jsonl'\n",
    "import json \n",
    "\n",
    "with open(path_to_json_file, 'r') as j:\n",
    "     json_data = [json.loads(line) for line in j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1800/1800 [00:00<00:00, 405399.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tweets=[]\n",
    "labels=[]\n",
    "for tweet in tqdm(json_data):\n",
    "    tot_cont = \"\"\n",
    "    for con in tweet['context']:\n",
    "        tot_cont+=con \n",
    "    tot_cont+=tweet['response']\n",
    "    tweets.append(tot_cont)\n",
    "    labels.append(tweet['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'target_text':labels,\n",
    "        'source_text':tweets}\n",
    " \n",
    "test = pd.DataFrame(data)\n",
    " \n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train = train.sample(frac = 1)\n",
    "train_data = train[:4500]\n",
    "val_data = train[4500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from simplet5 import SimpleT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleT5()\n",
    "model.from_pretrained(\"byt5\",\"google/byt5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# m = -1\n",
    "# mi=1000000000000\n",
    "# count=0\n",
    "# for index, row in tqdm(train_data.iterrows()):\n",
    "#     m = max(m,len(row['source_text']))\n",
    "#     mi=min(mi,len(row['source_text']))\n",
    "#     count+=len(row['source_text'])\n",
    "\n",
    "# print(m, mi)\n",
    "# print(count/4500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 299 M \n",
      "-----------------------------------------------------\n",
      "299 M     Trainable params\n",
      "0         Non-trainable params\n",
      "299 M     Total params\n",
      "1,198.551 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sm9669/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/sm9669/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 42\n",
      "/home/sm9669/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dea64b9965c463093c1d673cf081cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train(train_df=train_data, \n",
    "            eval_df=val_data, \n",
    "            source_max_token_len = 1024, \n",
    "            target_max_token_len = 128,\n",
    "            batch_size = 8,\n",
    "            max_epochs = 10,\n",
    "            use_gpu = True,\n",
    "            outputdir = \"epoch_10_outputs_Twitter\",\n",
    "            early_stopping_patience_epochs = 0\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simplet5 import SimpleT5\n",
    "model = SimpleT5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_model('byt5', '/scratch/sm9669/simpleT5-main/epoch_10_outputs_Twitter/simplet5-epoch-9-train-loss-0.0423-val-loss-0.0407')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [05:08,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [10:27,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [15:31,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "401it [20:27,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "501it [25:19,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "601it [30:33,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [35:50,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "801it [41:07,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "901it [46:47,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1001it [52:01,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1101it [56:42,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1201it [1:01:53,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1301it [1:06:24,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300 853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1401it [1:11:03,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400 920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1501it [1:16:12,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1601it [1:21:25,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600 1048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1701it [1:26:19,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1700 1115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1800it [1:31:07,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.72222222222223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "count=0\n",
    "value=0\n",
    "lis=[]\n",
    "for index, row in tqdm(test.iterrows()):\n",
    "    ans = model.predict(row['source_text'])\n",
    "    if ans[0]==row['target_text']:\n",
    "        count+=1\n",
    "    if value%100==0:\n",
    "        print(value,count)\n",
    "    value+=1\n",
    "    lis.append(ans[0])\n",
    "\n",
    "print(count*100/1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_list = ['SARCASM', 'NOT_SARCASM']\n",
    "for i in lis:\n",
    "    if i not in expected_list:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 10 epochs: 65.72222222222223\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on 10 epochs:\", count*100/1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
